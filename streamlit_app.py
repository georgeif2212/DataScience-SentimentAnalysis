import streamlit as st
import pandas as pd
import json
from pathlib import Path
from PIL import Image

st.set_page_config(
    page_title="AnÃ¡lisis de Sentimiento de Tweets",
    page_icon=":bar_chart:",
)

# ----------------------------------------------------------------------------
# Cargar datos desde JSON
DATA_PATH = Path(__file__).parent / "data/sentiment_results.json"
with open(DATA_PATH, "r", encoding="utf-8") as f:
    data = json.load(f)

tweets = pd.DataFrame(data["tweets"])
timeline = pd.DataFrame(data["timeline"])

# Convertir la columna de fecha en datetime
tweets["tweet_created"] = pd.to_datetime(tweets["tweet_created"])
timeline["date"] = pd.to_datetime(timeline["date"])

# ----------------------------------------------------------------------------
# TÃ­tulo y documentaciÃ³n
st.title("AnÃ¡lisis de Sentimiento de Tweets de AerolÃ­neas en Estados Unidos")

with st.expander("ğŸ“ DocumentaciÃ³n del proyecto"):
    st.markdown(
        """
    ### ğŸ“„ Origen del dataset:
    El dataset fue recolectado desde Kaggle y contiene mÃ¡s de 87,000 tweets relacionados con un tema especÃ­fico. Cada registro incluye texto, fecha de publicaciÃ³n y un identificador Ãºnico del tweet.

    ### ğŸ§¹ Preprocesamiento:
    Se utilizÃ³ la librerÃ­a **NLTK** (Natural Language Toolkit) por su robustez en tareas de procesamiento de lenguaje natural. Las etapas del preprocesamiento incluyeron:
    - ConversiÃ³n del texto a minÃºsculas.
    - EliminaciÃ³n de signos de puntuaciÃ³n, menciones, hashtags, URLs y caracteres no alfabÃ©ticos.
    - TokenizaciÃ³n usando `nltk.word_tokenize`.
    - EliminaciÃ³n de stopwords en inglÃ©s mediante `nltk.corpus.stopwords`.
    - LematizaciÃ³n con `WordNetLemmatizer` para reducir las palabras a su forma base (por ejemplo, *running* â†’ *run*), mejorando la consistencia del anÃ¡lisis.

    ### ğŸ¤– Modelo de anÃ¡lisis de sentimientos:
    Se utilizÃ³ **VADER (Valence Aware Dictionary and sEntiment Reasoner)**, una herramienta especializada en anÃ¡lisis de sentimientos de texto corto, especialmente eficaz con lenguaje informal como el que se encuentra en redes sociales. 
    Se eligiÃ³ VADER en lugar de TextBlob por su mayor precisiÃ³n en el anÃ¡lisis de textos con emoticonos, siglas y puntuaciÃ³n emocional como mayÃºsculas o signos de exclamaciÃ³n.

    Cada tweet fue etiquetado como **positivo**, **neutral** o **negativo**, segÃºn la puntuaciÃ³n compuesta (`compound`) calculada por VADER:
    - `compound â‰¥ 0.05`: Positivo  
    - `compound â‰¤ -0.05`: Negativo  
    - En otro caso: Neutral

    ### ğŸ“Š Resultados presentados:
    - **EstadÃ­sticas agregadas:** Cantidad y porcentaje de tweets por categorÃ­a de sentimiento.
    - **Visualizaciones:** 
        - GrÃ¡fico de barras con la distribuciÃ³n de sentimientos.
        - Serie temporal de la evoluciÃ³n de sentimientos por fecha.
        - Nubes de palabras generadas para cada tipo de sentimiento.
    - **ExploraciÃ³n de tweets:** Posibilidad de filtrar los comentarios por sentimiento y fecha.

    ### ğŸ“Œ Limitaciones:
    - Los resultados pueden verse afectados por la ambigÃ¼edad, sarcasmo o errores gramaticales.
    - El anÃ¡lisis solo considera el texto del tweet, ignorando contexto, imÃ¡genes o enlaces asociados.
    - VADER no es multilingÃ¼e, por lo tanto solo se analizaron tweets en inglÃ©s.

    ### ğŸ¯ Objetivo:
    Este proyecto busca reforzar habilidades en la limpieza y anÃ¡lisis de texto, asÃ­ como en la presentaciÃ³n dinÃ¡mica de resultados mediante una interfaz web interactiva.
    """
    )


# ----------------------------------------------------------------------------
# EstadÃ­sticas generales
st.subheader("ğŸ“Š EstadÃ­sticas Generales")
st.markdown("Porcentaje de cada categorÃ­a de sentimiento")

col1, col2 = st.columns(2)

with col1:
    st.image(
        "./data/grafico_porcentaje_sentimiento.png",
        caption="DistribuciÃ³n de Sentimientos",
    )

with col2:
    st.json(data["summary"])

# ----------------------------------------------------------------------------
# GrÃ¡fico de lÃ­nea: serie temporal de sentimientos
st.subheader("ğŸ“ˆ Sentimientos a lo largo del tiempo")

st.line_chart(
    timeline.set_index("date")[["positive", "neutral", "negative"]],
    use_container_width=True,
)

# ----------------------------------------------------------------------------
# Nube de palabras por sentimiento
st.subheader("â˜ï¸ Nube de palabras por sentimiento")

sentiment_option = st.selectbox(
    "Selecciona un sentimiento:", ["positive", "neutral", "negative"]
)

st.image(
    data["wordclouds"][sentiment_option],
    caption=f"Nube de palabras: {sentiment_option}",
)

# ----------------------------------------------------------------------------
# Filtros para tweets
st.subheader("ğŸ” Filtro de tweets")

col1, col2 = st.columns(2)

with col1:
    selected_sentiment = st.selectbox(
        "Filtrar por sentimiento:", ["Todos"] + list(tweets["sentiment"].unique())
    )

with col2:
    date_range = st.date_input(
        "Seleccionar rango de fechas:",
        value=(
            tweets["tweet_created"].min().date(),
            tweets["tweet_created"].max().date(),
        ),
    )

filtered_df = tweets.copy()
if selected_sentiment != "Todos":
    filtered_df = filtered_df[filtered_df["sentiment"] == selected_sentiment]

filtered_df = filtered_df[
    (filtered_df["tweet_created"].dt.date >= date_range[0])
    & (filtered_df["tweet_created"].dt.date <= date_range[1])
]

st.write(f"Se encontraron {len(filtered_df)} tweets con los filtros aplicados.")

st.dataframe(
    filtered_df[["tweet_created", "sentiment", "clean_text"]].head(20),
    use_container_width=True,
)

# ----------------------------------------------------------------------------
# Footer
st.markdown(
    """
---
**Creado por .** Proyecto acadÃ©mico de anÃ¡lisis de sentimientos con Streamlit.
"""
)
